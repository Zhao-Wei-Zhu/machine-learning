{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "dd701db1501b7a17"
      },
      "id": "dd701db1501b7a17"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, SpatialDropout2D\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:50:56.747114Z",
          "start_time": "2024-05-20T15:50:56.743575Z"
        },
        "id": "ee69c56fb90759d1"
      },
      "id": "ee69c56fb90759d1",
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RIGDq0vDrwr3ugdCFMEyXE-o2JoKj-5D\n",
            "From (redirected): https://drive.google.com/uc?id=1RIGDq0vDrwr3ugdCFMEyXE-o2JoKj-5D&confirm=t&uuid=c3b112e0-adae-4b88-bfaa-3d7ac190bf16\n",
            "To: /content/dataset/image.zip\n",
            "100%|██████████| 306M/306M [00:07<00:00, 42.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['image.zip', 'image']\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define the URL and data dir\n",
        "zip_url = 'https://drive.google.com/uc?id=1RIGDq0vDrwr3ugdCFMEyXE-o2JoKj-5D'\n",
        "data_dir = '/content/dataset'\n",
        "\n",
        "# Check if the directory exists, if not create it\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "# Download and extract the zip file\n",
        "zip_file = os.path.join(data_dir, 'image.zip')\n",
        "gdown.download(zip_url, zip_file, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "\n",
        "# List the files in the extracted folder\n",
        "extracted_files = os.listdir(data_dir)\n",
        "print(\"Extracted files:\", extracted_files)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T16:53:00.191599Z",
          "start_time": "2024-05-20T16:52:59.643949Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaba9b6a9439e7c3",
        "outputId": "eb92e9ef-a8fc-413d-d54e-84e082f1a68c"
      },
      "id": "eaba9b6a9439e7c3",
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "#relocate the dataset with 5 different name folders\n",
        "data_image= '/content/dataset/image'"
      ],
      "metadata": {
        "id": "c70cd8cdc1d4b8ae"
      },
      "id": "c70cd8cdc1d4b8ae",
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1957 images belonging to 5 classes.\n",
            "Found 486 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the data generators with a validation split\n",
        "# Create a data generator for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "   rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Create a data generator for validation\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Specify the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the training dataset\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    data_image,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,  # Consider reducing batch size if dataset is small\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "val_ds =  train_datagen.flow_from_directory(\n",
        "    data_image,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,  # Consistent with training batch size\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:51:13.224363Z",
          "start_time": "2024-05-20T15:51:13.151580Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a03224730d59455",
        "outputId": "834d3cc8-1120-42e7-f094-5fe6bc66fb4e"
      },
      "id": "a03224730d59455",
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(5, activation='softmax')(x)  # 5 classes\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:51:21.176699Z",
          "start_time": "2024-05-20T15:51:20.258333Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeb723d8b4e93f23",
        "outputId": "bcf388b3-9d0b-4622-b00b-e9557047141c"
      },
      "id": "aeb723d8b4e93f23",
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Create the complete model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:51:22.283275Z",
          "start_time": "2024-05-20T15:51:22.269903Z"
        },
        "id": "940b6d992d968687"
      },
      "id": "940b6d992d968687",
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:51:23.020824Z",
          "start_time": "2024-05-20T15:51:23.008551Z"
        },
        "id": "eb50dce24dda6792"
      },
      "id": "eb50dce24dda6792",
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Set up the early stopping and learning rate reduction callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:51:23.539831Z",
          "start_time": "2024-05-20T15:51:23.536779Z"
        },
        "id": "8d8ed20b466ff676"
      },
      "id": "8d8ed20b466ff676",
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "32/61 [==============>...............] - ETA: 50s - loss: 1.1335 - accuracy: 0.5908"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=train_ds.samples // train_ds.batch_size,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=val_ds.samples // val_ds.batch_size,\n",
        "    epochs=15,\n",
        "    callbacks=[ early_stopping, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:51:45.095319Z",
          "start_time": "2024-05-20T15:51:24.126349Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9385b098087a30e0",
        "outputId": "d5223db1-edd5-40d8-fc97-1922b0e8dd7a"
      },
      "id": "9385b098087a30e0",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Plot the training and validation accuracy and loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig('T&V.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-20T15:51:45.097316Z",
          "start_time": "2024-05-20T15:51:45.096321Z"
        },
        "id": "8c705a372956c371"
      },
      "id": "8c705a372956c371",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Evaluate the model using the validation set\n",
        "val_preds = model.predict(val_ds)\n",
        "val_preds_classes = np.argmax(val_preds, axis=1)\n",
        "\n",
        "true_classes = val_ds.classes\n",
        "class_labels = list(val_ds.class_indices.keys())\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-05-20T15:51:45.097316Z"
        },
        "id": "3912689f5b75641a"
      },
      "id": "3912689f5b75641a",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Generate a classification report\n",
        "print(classification_report(true_classes, val_preds_classes, target_names=class_labels))"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-05-20T15:51:45.098313Z"
        },
        "id": "e963e063f8725232"
      },
      "id": "e963e063f8725232",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(true_classes, val_preds_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.savefig('con.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-05-20T15:51:45.099310Z"
        },
        "id": "62f0940fc3b364f6"
      },
      "id": "62f0940fc3b364f6",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "6cda5ed996b231d9"
      },
      "id": "6cda5ed996b231d9",
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}